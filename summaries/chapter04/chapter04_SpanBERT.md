â€‹                       

# Chapter 4 BERT íŒŒìƒ ëª¨ë¸ 2

ì´ë²ˆ ì¥ì—ì„œ ë‹¤ë£¨ëŠ” BERTì˜ ë‹¤ì–‘í•œ í˜•íƒœì˜ íŒŒìƒ ëª¨ë¸

- ALBERT
- RoBERTa
- ELECTRA
- SpanBERT

## SpanBERT

ğŸ“„  **[SpanBERT: Improving Pre-training by Representing and Predicting Spans](https://arxiv.org/pdf/1907.10529.pdf)**

SpanBERTë€ text spanì„ ë” ì˜ í‘œí˜„í•˜ê³  ì˜ˆì¸¡í•˜ê¸° ìœ„í•´ ì„¤ê³„ëœ ì‚¬ì „ í•™ìŠµ ê¸°ë²•ì´ë‹¤.

- ë‹¤ìŒê³¼ ê°™ì€ ë°©ì‹ìœ¼ë¡œ BERTë¥¼ í™•ì¥í•˜ì˜€ë‹¤.

|                                               |                SpanBERT                |                  BERT                   |
| :-------------------------------------------: | :------------------------------------: | :-------------------------------------: |
|                **ë§ˆìŠ¤í‚¹ ë°©ë²•**                |        ì—°ì†ëœ ëœë¤ spans ë§ˆìŠ¤í‚¹        |            ëœë¤ í† í° ë§ˆìŠ¤í‚¹             |
| **ë§ˆìŠ¤í‚¹ëœ í† í° ì˜ˆì¸¡í•˜ê¸° ìœ„í•´ ì‚¬ìš©í•˜ëŠ” í‘œí˜„** | span ê²½ê³„ í‘œí˜„ì„ í•™ìŠµì‹œì¼œì„œ ì˜ˆì¸¡ (SBO) | ë§ˆìŠ¤í‚¹ëœ ê°œë³„ í† í°ì˜ í‘œí˜„ì„ ì´ìš©í•´ ì˜ˆì¸¡ |

<div style="text-align:center">SpanBERTì™€ BERT</div>

ğŸ¤” ê¸°ì¡´ ë§ì€ NLP tasksëŠ” **ë‘ ê°œ ì´ìƒì˜ text spanì˜ ê´€ê³„ ì¶”ë¡ **ì„ í¬í•¨í–ˆê³ , ì´ëŠ” self supervision tasksë¥¼ ë” ì–´ë µê²Œ í–ˆë‹¤.

â¡ï¸ SpanBERTëŠ” **span-level** ì‚¬ì „í•™ìŠµ ë°©ì‹ìœ¼ë¡œ í•­ìƒ BERTë³´ë‹¤ ì¢‹ì€ ì„±ëŠ¥ì„ ë‚¸ë‹¤.

- íŠ¹íˆ <u>span selection tasks</u>ì—ì„œ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë³´ì¸ë‹¤.

  - question answering
- coreference resolution (ìƒí˜¸ì°¸ì¡°í•´ê²°)
- ë°ì´í„°ë¥¼ ë” ì¶”ê°€í•˜ê±°ë‚˜ ëª¨ë¸ í¬ê¸°ë¥¼ í‚¤ìš°ì§€ ì•Šê³ , ì¢‹ì€ ì‚¬ì „í•™ìŠµ tasksì™€ objectivesë§Œìœ¼ë¡œë„ ì¢‹ì€ ì„±ëŠ¥ì„ ë‚¼ ìˆ˜ ìˆë‹¤ëŠ” ì˜ì˜ê°€ ìˆë‹¤.

### Model

- ì—°ì†ëœ ëœë¤ spans ë§ˆìŠ¤í‚¹
- span boundary objective (SBO) ë„ì…

- ë‹¨ì¼ ì—°ì† text segment ìƒ˜í”Œë§  â¡ï¸ BERTì˜ NSP ìƒëµ

#### Span Masking

`masking spans of full words using a geometric distribution based masking scheme`

- ì£¼ì–´ì§„ í† í° ì‹œí€€ìŠ¤ *X=(x1,â€¦,xn)* ì—ì„œ masking budget(e.g. 15% of X)ì´ ë‹¤ ì‚¬ìš©ë  ë•Œê¹Œì§€ text span ìƒ˜í”Œë§

1. ê° iteration ë§ˆë‹¤ span length(ë‹¨ì–´ ê°œìˆ˜)ë¥¼ ìƒ˜í”Œë§

   - ì§§ì€ spanìœ¼ë¡œ ì¹˜ìš°ì¹œ geometric distribution *ğ“µ ~ Geo(p)* ì—ì„œ ìƒ˜í”Œë§

2. ë§ˆìŠ¤í‚¹ë  spanì˜ ì‹œì‘ì ì„ ëœë¤(ê· ì¼)í•˜ê²Œ ë½‘ëŠ”ë‹¤.

   ì™„ì „í•œ ë‹¨ì–´ seqeunceë¥¼ ìƒ˜í”Œë§í•œë‹¤. (subword tokens X)

3. spanì— ìˆëŠ” ëª¨ë“  í† í°ë“¤ì„ [MASK] ë˜ëŠ” sampled tokensë¡œ ëŒ€ì²´í•œë‹¤. (span-level masking)

   *Cf. BERTëŠ” 80-10-10% ë¡œ ê° í† í°ì„ ê°œë³„ì ìœ¼ë¡œ ëŒ€ì²´*

#### Span Boundary Objective (SBO)

`optimizing an auxiliary span boundary objective (SBO) in addition to MLM`

span selection modelì€ ì¼ë°˜ì ìœ¼ë¡œ boundary í† í°ì„ ì´ìš©í•˜ì—¬ spanì˜ ê³ ì •ëœ ê¸¸ì´ í‘œí˜„ì„ ìƒì„±í•œë‹¤.

â¡ï¸ **boundary í† í°ì˜ í‘œí˜„ë§Œì„ ì´ìš©í•´ masked spanì˜ ê° í† í°ì„ ì˜ˆì¸¡í•˜ëŠ” <u>Span boundary objective(SBO)</u>** ë„ì…í–ˆë‹¤.

- SBOëŠ” ëª¨ë¸ì´ fine-tuning ì‹œì— ì‰½ê²Œ ì ‘ê·¼í•  ìˆ˜ ìˆëŠ” boundary í† í°ì— span-level ì •ë³´ë¥¼ ì €ì¥í•˜ê²Œ í•˜ì—¬ span selection modelì„ ì§€ì›í•œë‹¤.

- spanì— ìˆëŠ” ë§ˆìŠ¤í‚¹ëœ í† í°  `xi` *(target token: xi)* ì„ ì˜ˆì¸¡í•˜ëŠ” ë°©ë²•
  - xsì™€ xeë¥¼ ê°ê° ë§ˆìŠ¤í‚¹ëœ í† í°ì— ëŒ€í•œ í‘œí˜„ì˜ ì‹œì‘ê³¼ ì¢…ë£Œ ì§€ì ì´ë¼ê³  í•  ë•Œ, ë‹¤ìŒ 3ê°œì˜ ê°’ì„ ì‚¬ìš©í•œë‹¤.
    - external boundary tokens `xsâˆ’1` and `xe+1`
    - position embedding of the target token `piâˆ’s+1` (left boundary token xs-1ë¡œë¶€í„° ìƒëŒ€ ìœ„ì¹˜)

  - 3ê°œì˜ ê°’ì„ 2 layer feed-forward network with GeLU activations and layer normalization ì— ì…ë ¥í•˜ì—¬ ì–»ì€ ì¶œë ¥ê°’ì„ ì‚¬ìš©í•œë‹¤.

- SpanBERTì˜ ì†ì‹¤í•¨ìˆ˜ëŠ” MLMê³¼ SBO loss *(cross-entropy loss)*ë¥¼ ë”í•œ ê°’ì´ë‹¤.

#### Single-Sequence Training

BERTì˜ examplesëŠ” ë‘ ê°œì˜ text sequence *(X_A, X_B)* ë¥¼ ì‚¬ìš©í•˜ê³ , ë‘ sequenceì˜ ì—°ê²° ì—¬ë¶€ë¥¼ ì˜ˆì¸¡*(NSP)*í•˜ê²Œ ëª¨ë¸ì„ í•™ìŠµì‹œì¼°ë‹¤. *(bi-sequence training with NSP)*

í•˜ì§€ë§Œ single-sequence trainingì´ bi-sequence training with NSPë³´ë‹¤ ìš°ìˆ˜í–ˆê³ , ì´ìœ ëŠ” ë‹¤ìŒê³¼ ê°™ì„ ê²ƒì´ë¼ê³  ê°€ì •í–ˆë‹¤.

*: bi-sequence trainingì€ ëª¨ë¸ì´ ë” ê¸´ ë²”ìœ„ì˜ featuresë¥¼ í•™ìŠµí•˜ëŠ” ê²ƒì„ ë°©í•´í•˜ê³ , ê²°ê³¼ì ìœ¼ë¡œ ë§ì€ downstream tasks ì—ì„œ ì„±ëŠ¥ì„ ì €í•˜ì‹œí‚¨ë‹¤.*

â¡ï¸ **NSP objectiveê³¼ two-segment sampling procedureë¥¼ ëª¨ë‘ ì œê±°í•˜ê³ ,** ë‘ ê°œì˜ half-segmentsë¥¼ í•©ì³ì„œ nê°œì˜ í† í°ì´ ì•„ë‹Œ, 

**ìµœëŒ€ n=512ì˜ í† í°ì˜ ë‹¨ì¼ ì—°ì† segmentë¥¼ ìƒ˜í”Œë§**í•´ì„œ ë‹¤ì–‘í•œ downstream tasksì˜ ì„±ëŠ¥ì„ í–¥ìƒì‹œì¼°ë‹¤.

---

![An illustration of SpanBERT training. The span an American football game is masked. The SBO uses the output representations of the boundary tokens, x4 and x9 (in blue), to predict each token in the masked span. The equation shows the MLM and SBO loss terms for predicting the token, football (in pink), which as marked by the position embedding p3, is the third token from x4.](https://mitp.silverchair-cdn.com/mitp/content_public/journal/tacl/8/10.1162_tacl_a_00300/9/00300f01c.png?Expires=1647335036&Signature=2Z94mvu96t5Rlhgzz07oMo1qE11rmtqyU3ZlAozrJPX~h3m8vZa9siuGBi~Ni4uHuPCJjKD4E0n0WafeXohbpmcDboOJufNCXQIoHUU4FCsvx3nWQQmxVVFbSL1OOdHfrBAS-dggk3Fmoqgy9lxMWaOF-IfvhDN-M0FZDp7h6hqgOPjQOSGyo1rhxV9o8qcFAHvftZj7llwQ4SLmx1Tx7uJ~p5cAK2sZtzDfqNdqSQvc2~gM2eCPykLw72Wen1p-jRaqNlu6y76YBAfSbcphHD6mhPx0K8fnPdAbGA7GlIgpylRCay8lopV0p0-pFQ6JmOdpdvEyvWHlbVjekxgMUg__&Key-Pair-Id=APKAIE5G5CRDK6RD3PGA)

<div style="text-align:center">SpanBERT í•™ìŠµ ê³¼ì •</div> 

### Tasks

- Extractive Question Answering
  - ì§§ì€ ê¸€ê³¼ ì§ˆë¬¸ì„ ì…ë ¥í•œ í›„ì— ê¸€ì—ì„œ ë‹µìœ¼ë¡œ ì—°ì†ì ì¸ text spanì„ ì„ íƒí•˜ëŠ” task

- Coreference Resolution

  - ë™ì¼í•œ ê°œì²´(entity)ë¥¼ í‘œí˜„í•˜ëŠ” ë‹¤ì–‘í•œ ë‹¨ì–´(mention)ë“¤ì„ ì°¾ì•„ ì—°ê²°í•´ì£¼ëŠ” task

    *[Coreference Resolution ê´€ë ¨ ì„¤ëª… ë° ë…¼ë¬¸ì´ ì •ë¦¬ëœ ë¸”ë¡œê·¸](https://jjdeeplearning.tistory.com/26)*

- Relation Extraction

  - ë‘ spanì´ ë“¤ì–´ìˆëŠ” í•œ ë¬¸ì¥ì´ ì£¼ì–´ì¡Œì„ ë•Œ 42ê°œì˜ ì‚¬ì „ ì •ì˜ëœ ê´€ê³„ íƒ€ì…ìœ¼ë¡œë¶€í„° span ì‚¬ì´ì˜ ê´€ê³„ë¥¼ ì˜ˆì¸¡í•˜ëŠ” task

- GLUE

  - General Language Understanding Evaluation (GLUE) benchmarkëŠ” 9ê°œì˜ sentence-level ë¶„ë¥˜ tasksë¡œ êµ¬ì„±

### Results

- SpanBERTëŠ” ê±°ì˜ ëª¨ë“  taskì— ëŒ€í•´ BERTë³´ë‹¤ ë›°ì–´ë‚˜ë‹¤.
- SpanBERTëŠ” íŠ¹íˆ extractive question answeringì— ì¢‹ë‹¤.
- single-sequence trainingì´ bi-sequence with NSP ë³´ë‹¤ ìƒë‹¹íˆ ì˜ ì‘ë™í•œë‹¤.

### Summary

- ì´ ë…¼ë¬¸ì€ span ê¸°ë°˜ ì‚¬ì „ í•™ìŠµ ë°©ì‹ì¸ SpanBERTë¥¼ ì œì‹œí–ˆë‹¤.

- SpanBERTëŠ” BERTë¥¼ í™•ì¥í–ˆë‹¤.

  â€‹	(1) random í† í° ëŒ€ì‹ , ì—°ì†ì ì¸ ëœë¤ spanì„ ë§ˆìŠ¤í‚¹í•œë‹¤.

  â€‹	(2) ê°œë³„ í† í° í‘œí˜„ì´ ì•„ë‹Œ, span ê²½ê³„ í‘œí˜„ì„ í•™ìŠµì‹œì¼œ ë§ˆìŠ¤í‚¹ëœ spanì˜ ì „ì²´ ë‚´ìš©ì„ ì˜ˆì¸¡í•œë‹¤.

- SpanBERTëŠ” ì—¬ëŸ¬ taskì— ëŒ€í•´ ëª¨ë“  BERT baselinesë¥¼ ë›°ì–´ë„˜ì—ˆë‹¤.

- SpanBERTëŠ” span selection tasksì— íŠ¹íˆ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì¸ë‹¤.

## ì‚¬ì „ í•™ìŠµëœ SpanBERTë¥¼ ì§ˆë¬¸-ì‘ë‹µ íƒœìŠ¤í¬ì— ì ìš©í•˜ê¸°

```python
from transformers import pipeline

qa_pipeline = pipeline(
    "question-answering",
    model="mrm8488/spanbert-large-finetuned-squadv2",
    tokenizer="SpanBERT/spanbert-large-cased"
)

results = qa_pipeline({
    'question': "What is machine learning?",
    'context': "Machine learning is a subset of artificial intelligence. It is widely for creating a variety of applications such as email filtering and computer vision"
})

print(results['answer'])  # a subset of artificial intelligence
```

*SpanBertëŠ” í…ìŠ¤íŠ¸ ë²”ìœ„ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ì‘ì—…ì— ë§ì´ ì‚¬ìš©ëœë‹¤.*

## ì°¸ê³  ìë£Œ

- êµ¬ê¸€ BERTì˜ ì •ì„ [book](http://www.yes24.com/Product/Goods/104491152)