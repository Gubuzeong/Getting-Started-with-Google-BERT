{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a5da9b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ktrain\n",
      "  Downloading ktrain-0.29.3.tar.gz (25.3 MB)\n",
      "     --------------------------------------- 25.3/25.3 MB 59.9 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting scikit-learn==0.24.2\n",
      "  Downloading scikit_learn-0.24.2-cp38-cp38-win_amd64.whl (6.9 MB)\n",
      "     ---------------------------------------- 6.9/6.9 MB 73.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in c:\\users\\shyram\\anaconda3\\lib\\site-packages (from ktrain) (3.3.4)\n",
      "Requirement already satisfied: pandas>=1.0.1 in c:\\users\\shyram\\anaconda3\\lib\\site-packages (from ktrain) (1.2.4)\n",
      "Collecting fastprogress>=0.1.21\n",
      "  Downloading fastprogress-1.0.2-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\shyram\\anaconda3\\lib\\site-packages (from ktrain) (2.25.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\shyram\\anaconda3\\lib\\site-packages (from ktrain) (1.0.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\shyram\\anaconda3\\lib\\site-packages (from ktrain) (20.9)\n",
      "Collecting langdetect\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
      "     ---------------------------------------- 981.5/981.5 KB ? eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting jieba\n",
      "  Downloading jieba-0.42.1.tar.gz (19.2 MB)\n",
      "     --------------------------------------- 19.2/19.2 MB 73.1 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting cchardet\n",
      "  Downloading cchardet-2.1.7-cp38-cp38-win_amd64.whl (115 kB)\n",
      "     -------------------------------------- 115.2/115.2 KB 6.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: chardet in c:\\users\\shyram\\anaconda3\\lib\\site-packages (from ktrain) (4.0.0)\n",
      "Collecting syntok==1.3.3\n",
      "  Downloading syntok-1.3.3-py3-none-any.whl (22 kB)\n",
      "Collecting seqeval==0.0.19\n",
      "  Downloading seqeval-0.0.19.tar.gz (30 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting transformers==4.10.3\n",
      "  Downloading transformers-4.10.3-py3-none-any.whl (2.8 MB)\n",
      "     ---------------------------------------- 2.8/2.8 MB 88.8 MB/s eta 0:00:00\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.96-cp38-cp38-win_amd64.whl (1.1 MB)\n",
      "     ---------------------------------------- 1.1/1.1 MB 67.6 MB/s eta 0:00:00\n",
      "Collecting keras_bert>=0.86.0\n",
      "  Downloading keras-bert-0.89.0.tar.gz (25 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting whoosh\n",
      "  Downloading Whoosh-2.7.4-py2.py3-none-any.whl (468 kB)\n",
      "     ------------------------------------- 468.8/468.8 KB 30.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\shyram\\anaconda3\\lib\\site-packages (from scikit-learn==0.24.2->ktrain) (2.1.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\shyram\\anaconda3\\lib\\site-packages (from scikit-learn==0.24.2->ktrain) (1.20.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\shyram\\anaconda3\\lib\\site-packages (from scikit-learn==0.24.2->ktrain) (1.6.2)\n",
      "Requirement already satisfied: Keras>=2.2.4 in c:\\users\\shyram\\anaconda3\\lib\\site-packages (from seqeval==0.0.19->ktrain) (2.7.0)\n",
      "Requirement already satisfied: regex in c:\\users\\shyram\\anaconda3\\lib\\site-packages (from syntok==1.3.3->ktrain) (2021.4.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\shyram\\anaconda3\\lib\\site-packages (from transformers==4.10.3->ktrain) (5.4.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\shyram\\anaconda3\\lib\\site-packages (from transformers==4.10.3->ktrain) (3.0.12)\n",
      "Collecting tokenizers<0.11,>=0.10.1\n",
      "  Downloading tokenizers-0.10.3-cp38-cp38-win_amd64.whl (2.0 MB)\n",
      "     ---------------------------------------- 2.0/2.0 MB 64.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: huggingface-hub>=0.0.12 in c:\\users\\shyram\\anaconda3\\lib\\site-packages (from transformers==4.10.3->ktrain) (0.4.0)\n",
      "Requirement already satisfied: sacremoses in c:\\users\\shyram\\anaconda3\\lib\\site-packages (from transformers==4.10.3->ktrain) (0.0.47)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\shyram\\anaconda3\\lib\\site-packages (from transformers==4.10.3->ktrain) (4.59.0)\n",
      "Collecting keras-transformer==0.40.0\n",
      "  Downloading keras-transformer-0.40.0.tar.gz (9.7 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting keras-pos-embd==0.13.0\n",
      "  Downloading keras-pos-embd-0.13.0.tar.gz (5.6 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting keras-multi-head==0.29.0\n",
      "  Downloading keras-multi-head-0.29.0.tar.gz (13 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting keras-layer-normalization==0.16.0\n",
      "  Downloading keras-layer-normalization-0.16.0.tar.gz (3.9 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting keras-position-wise-feed-forward==0.8.0\n",
      "  Downloading keras-position-wise-feed-forward-0.8.0.tar.gz (4.1 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting keras-embed-sim==0.10.0\n",
      "  Downloading keras-embed-sim-0.10.0.tar.gz (3.6 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting keras-self-attention==0.51.0\n",
      "  Downloading keras-self-attention-0.51.0.tar.gz (11 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\shyram\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->ktrain) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\shyram\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->ktrain) (1.3.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\shyram\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->ktrain) (8.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\shyram\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->ktrain) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\shyram\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->ktrain) (0.10.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\shyram\\anaconda3\\lib\\site-packages (from pandas>=1.0.1->ktrain) (2021.1)\n",
      "Requirement already satisfied: six in c:\\users\\shyram\\anaconda3\\lib\\site-packages (from langdetect->ktrain) (1.15.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\shyram\\anaconda3\\lib\\site-packages (from requests->ktrain) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\shyram\\anaconda3\\lib\\site-packages (from requests->ktrain) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shyram\\anaconda3\\lib\\site-packages (from requests->ktrain) (2020.12.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\shyram\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.0.12->transformers==4.10.3->ktrain) (3.7.4.3)\n",
      "Requirement already satisfied: click in c:\\users\\shyram\\anaconda3\\lib\\site-packages (from sacremoses->transformers==4.10.3->ktrain) (7.1.2)\n",
      "Building wheels for collected packages: ktrain, seqeval, keras_bert, keras-transformer, keras-embed-sim, keras-layer-normalization, keras-multi-head, keras-pos-embd, keras-position-wise-feed-forward, keras-self-attention, jieba, langdetect\n",
      "  Building wheel for ktrain (setup.py): started\n",
      "  Building wheel for ktrain (setup.py): finished with status 'done'\n",
      "  Created wheel for ktrain: filename=ktrain-0.29.3-py3-none-any.whl size=25295401 sha256=1455f83b354cef5a321ad1f6b092c4a60df38cfc9958278fed03654b5d3ad991\n",
      "  Stored in directory: c:\\users\\shyram\\appdata\\local\\pip\\cache\\wheels\\e4\\04\\35\\785e4d64090aa723d2731def6d883294c9e501d605330a34a2\n",
      "  Building wheel for seqeval (setup.py): started\n",
      "  Building wheel for seqeval (setup.py): finished with status 'done'\n",
      "  Created wheel for seqeval: filename=seqeval-0.0.19-py3-none-any.whl size=9918 sha256=46a5f115cfbfbb78870a1cf01600f490346181296e507243b51fc3c7c94daa82\n",
      "  Stored in directory: c:\\users\\shyram\\appdata\\local\\pip\\cache\\wheels\\58\\e5\\9e\\2f94312239a6753267da6ceafe12d614603b78d308676df5e2\n",
      "  Building wheel for keras_bert (setup.py): started\n",
      "  Building wheel for keras_bert (setup.py): finished with status 'done'\n",
      "  Created wheel for keras_bert: filename=keras_bert-0.89.0-py3-none-any.whl size=33515 sha256=d6da838bbc2aff38bcd8f19bb7213e651f932924c14c9e3e5320cdb62e20f2b8\n",
      "  Stored in directory: c:\\users\\shyram\\appdata\\local\\pip\\cache\\wheels\\a1\\34\\ed\\6bbd71716d7bcea30d75e8bc5aeb94f4cb52636295c8343534\n",
      "  Building wheel for keras-transformer (setup.py): started\n",
      "  Building wheel for keras-transformer (setup.py): finished with status 'done'\n",
      "  Created wheel for keras-transformer: filename=keras_transformer-0.40.0-py3-none-any.whl size=12303 sha256=1ba99df7f26ee290aedbfe1b3ab73a846e6e570d0c4d220be1f0066f0a7dc1a5\n",
      "  Stored in directory: c:\\users\\shyram\\appdata\\local\\pip\\cache\\wheels\\07\\cd\\a7\\a8fa93f7e177eee0101fed63179f7a2fa3b53671ffaad82bfd\n",
      "  Building wheel for keras-embed-sim (setup.py): started\n",
      "  Building wheel for keras-embed-sim (setup.py): finished with status 'done'\n",
      "  Created wheel for keras-embed-sim: filename=keras_embed_sim-0.10.0-py3-none-any.whl size=3959 sha256=b288a68a6096c921b925bdb1ac95654e6ee5eaf06b08853f4f13c5985681a1af\n",
      "  Stored in directory: c:\\users\\shyram\\appdata\\local\\pip\\cache\\wheels\\59\\bd\\9a\\ec6e575aaa50687d7af968bde7ce710b542eeaa9ee7978d4ba\n",
      "  Building wheel for keras-layer-normalization (setup.py): started\n",
      "  Building wheel for keras-layer-normalization (setup.py): finished with status 'done'\n",
      "  Created wheel for keras-layer-normalization: filename=keras_layer_normalization-0.16.0-py3-none-any.whl size=4667 sha256=8c39da930aba3b73fd42154bf464369b33c5a43ac89e121967843b6d5c0489cc\n",
      "  Stored in directory: c:\\users\\shyram\\appdata\\local\\pip\\cache\\wheels\\d7\\2b\\f4\\28f4bab995fa99c26b761bc7f9aeb5bf6c81e9be6ccd0b853b\n",
      "  Building wheel for keras-multi-head (setup.py): started\n",
      "  Building wheel for keras-multi-head (setup.py): finished with status 'done'\n",
      "  Created wheel for keras-multi-head: filename=keras_multi_head-0.29.0-py3-none-any.whl size=14993 sha256=733a14b20ea503abca3d42af053e53322a610d53f337aef7561ec215de2e7a96\n",
      "  Stored in directory: c:\\users\\shyram\\appdata\\local\\pip\\cache\\wheels\\91\\eb\\bc\\ce4bb467f5a7db6727f148f70bb0e52a62ef7edd41a19c8bdd\n",
      "  Building wheel for keras-pos-embd (setup.py): started\n",
      "  Building wheel for keras-pos-embd (setup.py): finished with status 'done'\n",
      "  Created wheel for keras-pos-embd: filename=keras_pos_embd-0.13.0-py3-none-any.whl size=6960 sha256=7d3c1ad9cba1c0bf911fb49998e81e14144f957331c4eeee1d811a9eadca5d51\n",
      "  Stored in directory: c:\\users\\shyram\\appdata\\local\\pip\\cache\\wheels\\91\\c4\\ff\\7e13e4f102c3b7d73ff075a50fe3266f3ec2de898d5493a8a2\n",
      "  Building wheel for keras-position-wise-feed-forward (setup.py): started\n",
      "  Building wheel for keras-position-wise-feed-forward (setup.py): finished with status 'done'\n",
      "  Created wheel for keras-position-wise-feed-forward: filename=keras_position_wise_feed_forward-0.8.0-py3-none-any.whl size=4983 sha256=ff8f5f76b40c7133fabe33d5fe2e87b01de7b4b6d996b73213ad5242bffc3728\n",
      "  Stored in directory: c:\\users\\shyram\\appdata\\local\\pip\\cache\\wheels\\f2\\15\\39\\59861ed531ef6c7c75810500eb22c68a425f82dde31d68630a\n",
      "  Building wheel for keras-self-attention (setup.py): started\n",
      "  Building wheel for keras-self-attention (setup.py): finished with status 'done'\n",
      "  Created wheel for keras-self-attention: filename=keras_self_attention-0.51.0-py3-none-any.whl size=18911 sha256=5f59132d1aaa25f8bdcef54b3e0cd61f7033272bed4e0b56803049862ed43bd2\n",
      "  Stored in directory: c:\\users\\shyram\\appdata\\local\\pip\\cache\\wheels\\ac\\13\\2d\\3de7c76f618a8d162884ac5b726a8c2242ad88afa370f1e62f\n",
      "  Building wheel for jieba (setup.py): started\n",
      "  Building wheel for jieba (setup.py): finished with status 'done'\n",
      "  Created wheel for jieba: filename=jieba-0.42.1-py3-none-any.whl size=19314477 sha256=570f36b42086fdc59069025941a9e507a31bbd3917768d4dd9e19a16174d6999\n",
      "  Stored in directory: c:\\users\\shyram\\appdata\\local\\pip\\cache\\wheels\\ca\\38\\d8\\dfdfe73bec1d12026b30cb7ce8da650f3f0ea2cf155ea018ae\n",
      "  Building wheel for langdetect (setup.py): started\n",
      "  Building wheel for langdetect (setup.py): finished with status 'done'\n",
      "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993221 sha256=db8f735b45488281b98f2cf3550940234dc195d8acc581c99cb67594467b91cf\n",
      "  Stored in directory: c:\\users\\shyram\\appdata\\local\\pip\\cache\\wheels\\13\\c7\\b0\\79f66658626032e78fc1a83103690ef6797d551cb22e56e734\n",
      "Successfully built ktrain seqeval keras_bert keras-transformer keras-embed-sim keras-layer-normalization keras-multi-head keras-pos-embd keras-position-wise-feed-forward keras-self-attention jieba langdetect\n",
      "Installing collected packages: whoosh, tokenizers, sentencepiece, jieba, cchardet, syntok, seqeval, langdetect, keras-self-attention, keras-position-wise-feed-forward, keras-pos-embd, keras-layer-normalization, keras-embed-sim, fastprogress, scikit-learn, keras-multi-head, transformers, keras-transformer, keras_bert, ktrain\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.11.4\n",
      "    Uninstalling tokenizers-0.11.4:\n",
      "      Successfully uninstalled tokenizers-0.11.4\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 0.24.1\n",
      "    Uninstalling scikit-learn-0.24.1:\n",
      "      Successfully uninstalled scikit-learn-0.24.1\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.16.2\n",
      "    Uninstalling transformers-4.16.2:\n",
      "      Successfully uninstalled transformers-4.16.2\n",
      "Successfully installed cchardet-2.1.7 fastprogress-1.0.2 jieba-0.42.1 keras-embed-sim-0.10.0 keras-layer-normalization-0.16.0 keras-multi-head-0.29.0 keras-pos-embd-0.13.0 keras-position-wise-feed-forward-0.8.0 keras-self-attention-0.51.0 keras-transformer-0.40.0 keras_bert-0.89.0 ktrain-0.29.3 langdetect-1.0.9 scikit-learn-0.24.2 sentencepiece-0.1.96 seqeval-0.0.19 syntok-1.3.3 tokenizers-0.10.3 transformers-4.10.3 whoosh-2.7.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.3; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the 'c:\\users\\shyram\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install ktrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05ec235f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ktrain\n",
    "from ktrain import text\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb769e60",
   "metadata": {},
   "source": [
    "**json 파일 다운로드**  \n",
    "https://drive.google.com/uc?id=1-8urBLVtFuuvAVHi0s000e7r0KPUgt9f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "687bb64b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A3EBHHCZO6V2A4</td>\n",
       "      <td>5555991584</td>\n",
       "      <td>Amaranth \"music fan\"</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>It's hard to believe \"Memory of Trees\" came ou...</td>\n",
       "      <td>5</td>\n",
       "      <td>Enya's last great album</td>\n",
       "      <td>1158019200</td>\n",
       "      <td>09 12, 2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AZPWAXJG9OJXV</td>\n",
       "      <td>5555991584</td>\n",
       "      <td>bethtexas</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>A clasically-styled and introverted album, Mem...</td>\n",
       "      <td>5</td>\n",
       "      <td>Enya at her most elegant</td>\n",
       "      <td>991526400</td>\n",
       "      <td>06 3, 2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A38IRL0X2T4DPF</td>\n",
       "      <td>5555991584</td>\n",
       "      <td>bob turnley</td>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>I never thought Enya would reach the sublime h...</td>\n",
       "      <td>5</td>\n",
       "      <td>The best so far</td>\n",
       "      <td>1058140800</td>\n",
       "      <td>07 14, 2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A22IK3I6U76GX0</td>\n",
       "      <td>5555991584</td>\n",
       "      <td>Calle</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>This is the third review of an irish album I w...</td>\n",
       "      <td>5</td>\n",
       "      <td>Ireland produces good music.</td>\n",
       "      <td>957312000</td>\n",
       "      <td>05 3, 2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A1AISPOIIHTHXX</td>\n",
       "      <td>5555991584</td>\n",
       "      <td>Cloud \"...\"</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>Enya, despite being a successful recording art...</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5; music to dream to</td>\n",
       "      <td>1200528000</td>\n",
       "      <td>01 17, 2008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin          reviewerName helpful  \\\n",
       "0  A3EBHHCZO6V2A4  5555991584  Amaranth \"music fan\"  [3, 3]   \n",
       "1   AZPWAXJG9OJXV  5555991584             bethtexas  [0, 0]   \n",
       "2  A38IRL0X2T4DPF  5555991584           bob turnley  [2, 2]   \n",
       "3  A22IK3I6U76GX0  5555991584                 Calle  [1, 1]   \n",
       "4  A1AISPOIIHTHXX  5555991584           Cloud \"...\"  [1, 1]   \n",
       "\n",
       "                                          reviewText  overall  \\\n",
       "0  It's hard to believe \"Memory of Trees\" came ou...        5   \n",
       "1  A clasically-styled and introverted album, Mem...        5   \n",
       "2  I never thought Enya would reach the sublime h...        5   \n",
       "3  This is the third review of an irish album I w...        5   \n",
       "4  Enya, despite being a successful recording art...        4   \n",
       "\n",
       "                        summary  unixReviewTime   reviewTime  \n",
       "0       Enya's last great album      1158019200  09 12, 2006  \n",
       "1      Enya at her most elegant       991526400   06 3, 2001  \n",
       "2               The best so far      1058140800  07 14, 2003  \n",
       "3  Ireland produces good music.       957312000   05 3, 2000  \n",
       "4        4.5; music to dream to      1200528000  01 17, 2008  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json(r'reviews_Digital_Music_5.json',lines=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "891bd472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It's hard to believe \"Memory of Trees\" came ou...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A clasically-styled and introverted album, Mem...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I never thought Enya would reach the sublime h...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This is the third review of an irish album I w...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Enya, despite being a successful recording art...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  overall\n",
       "0  It's hard to believe \"Memory of Trees\" came ou...        5\n",
       "1  A clasically-styled and introverted album, Mem...        5\n",
       "2  I never thought Enya would reach the sublime h...        5\n",
       "3  This is the third review of an irish album I w...        5\n",
       "4  Enya, despite being a successful recording art...        4"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[['reviewText','overall']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "788cc587",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = {1:'negative',2:'negative',3:'negative', 4:'positive',5:'positive'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7a8f268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It's hard to believe \"Memory of Trees\" came ou...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A clasically-styled and introverted album, Mem...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I never thought Enya would reach the sublime h...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This is the third review of an irish album I w...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Enya, despite being a successful recording art...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText sentiment\n",
       "0  It's hard to believe \"Memory of Trees\" came ou...  positive\n",
       "1  A clasically-styled and introverted album, Mem...  positive\n",
       "2  I never thought Enya would reach the sublime h...  positive\n",
       "3  This is the third review of an irish album I w...  positive\n",
       "4  Enya, despite being a successful recording art...  positive"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'] = df['overall'].map(sentiment)\n",
    "df = df[['reviewText','sentiment']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af390d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['negative', 'positive']\n",
      "       negative  positive\n",
      "38430       0.0       1.0\n",
      "12842       0.0       1.0\n",
      "6965        0.0       1.0\n",
      "8671        0.0       1.0\n",
      "15755       0.0       1.0\n",
      "['negative', 'positive']\n",
      "       negative  positive\n",
      "50214       0.0       1.0\n",
      "53169       1.0       0.0\n",
      "4119        0.0       1.0\n",
      "37339       1.0       0.0\n",
      "23168       1.0       0.0\n",
      "downloading pretrained BERT model (uncased_L-12_H-768_A-12.zip)...\n",
      "[██████████████████████████████████████████████████]\n",
      "extracting pretrained BERT model...\n",
      "done.\n",
      "\n",
      "cleanup downloaded zip...\n",
      "done.\n",
      "\n",
      "preprocessing train...\n",
      "language: en\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "done."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Multi-Label? False\n",
      "preprocessing test...\n",
      "language: en\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "done."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test), preproc = text.texts_from_df(train_df = df, \n",
    "                                                                   text_column = 'reviewText',\n",
    "                                                                   label_columns=['sentiment'],\n",
    "                                                                   maxlen=100, \n",
    "                                                                   max_features=100000,\n",
    "                                                                   preprocess_mode='bert',\n",
    "                                                                   val_pct=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "326a5ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Multi-Label? False\n",
      "maxlen is 100\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "model = text.text_classifier(name='bert', train_data = (x_train, y_train) , preproc=preproc, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1353ad53",
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = ktrain.get_learner(model = model, \n",
    "                             train_data=(x_train, y_train), \n",
    "                             val_data=(x_test, y_test), \n",
    "                             batch_size=32, \n",
    "                             use_multiprocessing = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12f9673b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "begin training using onecycle policy with max lr of 2e-05...\n",
      "1820/1820 [==============================] - 368s 196ms/step - loss: 0.3300 - accuracy: 0.8638 - val_loss: 0.2699 - val_accuracy: 0.8873\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x209a11d5fa0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.fit_onecycle(lr=2e-5, epochs=1,checkpoint_folder='output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9ba019d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = ktrain.get_predictor(learner.model, preproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c562869f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.predict('I loved the song')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "624fdd88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'negative'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.predict('I hated the song')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
